{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_jax_intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOiqMBdzgmkGJJ4klZjCiBy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxmatical/jax_projects/blob/master/01_jax_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XHcCjIga2yM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax\n",
        "import jax.numpy as np\n",
        "import numpy as onp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEmySuxZdDGU",
        "colab_type": "text"
      },
      "source": [
        "# Training XOR in Jax with nn with 1 hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZqmci8AfxqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b286b857-25a5-4ea7-e23a-753d407f68e5"
      },
      "source": [
        "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "print(inputs.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3OO4UUebVVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def net(params, x):\n",
        "    w1, b1, w2, b2 = params # weights and \n",
        "    h1 = np.maximum(np.dot(w1, x)+ b1, 0) # matmul then relu (which is basically max(0, out))\n",
        "\n",
        "    out = sigmoid(np.dot(w2, h1) + b2)\n",
        "    return out\n",
        "\n",
        "# cross entropy loss\n",
        "def loss(params, x, y):\n",
        "    out = net(params, x)\n",
        "    cross_entropy = -y*np.log(out) - (1-y)*np.log(1-out)\n",
        "    return cross_entropy\n",
        "\n",
        "\n",
        "# Utility function for testing whether the net produces the correct\n",
        "# output for all possible inputs\n",
        "def test_all_inputs(inputs, params):\n",
        "    predictions = [int(net(params, inp) > 0.5) for inp in inputs]\n",
        "    for inp, out in zip(inputs, predictions):\n",
        "        print(inp, '->', out)\n",
        "    return (predictions == [onp.bitwise_xor(*inp) for inp in inputs])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FdWLfNSeo0b",
        "colab_type": "text"
      },
      "source": [
        "Initialize weights\n",
        "\n",
        "note: done in onp because it's easier than using jax's rng\n",
        "\n",
        "x shape = [n, ni]\n",
        "\n",
        "w = [nh, ni]\n",
        "\n",
        "np.dot(w, x) -> $x^{t}w$ gives shape [n, nh]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qV0Emuhg5_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ??onp.random.randn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01RiVwcveoYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_params():\n",
        "    # returns samples from a gaussian distribution\n",
        "    return [\n",
        "        onp.random.randn(3, 2),  # w1 shape = [nh, ni], inpu\n",
        "        onp.random.randn(3),  # b1\n",
        "        onp.random.randn(3),  # w2\n",
        "        onp.random.randn(),  #b2\n",
        "    ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSq0T6NIethl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute gradients\n",
        "loss_grad = jax.grad(loss) # that was easy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjOy1QiJhIf5",
        "colab_type": "text"
      },
      "source": [
        "start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q04RUHSXgIxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f953ce22-aa06-439f-fe3f-1f4977049686"
      },
      "source": [
        "%%time\n",
        "params = init_params()\n",
        "lr = 1e-1\n",
        "for i in range(1000):\n",
        "    x = inputs[onp.random.choice(inputs.shape[0])] # grab 1 sample\n",
        "    y = onp.bitwise_xor(*x) # get the output\n",
        "    grads = loss_grad(params, x, y)\n",
        "    #update gradients\n",
        "    params = [p-lr*g for p, g in zip(params, grads)]\n",
        "\n",
        "    # print stats\n",
        "    if (i+1)%100 == 0:\n",
        "        print(f'Iteration {i+1}')\n",
        "        print(test_all_inputs(inputs, params))\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 100\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 1\n",
            "False\n",
            "Iteration 200\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 1\n",
            "False\n",
            "Iteration 300\n",
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 400\n",
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 500\n",
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 600\n",
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 700\n",
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 800\n",
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 900\n",
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 1000\n",
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "CPU times: user 18 s, sys: 3.45 s, total: 21.4 s\n",
            "Wall time: 16.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWY2cQhxklsR",
        "colab_type": "text"
      },
      "source": [
        "## Using jit compile with  `jax.jit`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wn_2Fz0hK2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_grad = jax.jit(jax.grad(loss)) # just add jax.jit in front of it"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV30P7Ixk5sX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3f37597-f49d-4fdf-d51b-3bf8132450f6"
      },
      "source": [
        "%%time\n",
        "params = init_params()\n",
        "lr = 1e-1\n",
        "for i in range(1000):\n",
        "    x = inputs[onp.random.choice(inputs.shape[0])] # grab 1 sample\n",
        "    y = onp.bitwise_xor(*x) # get the output\n",
        "    grads = loss_grad(params, x, y)\n",
        "    #update gradients\n",
        "    params = [p-lr*g for p, g in zip(params, grads)]\n",
        "\n",
        "    # print stats\n",
        "    if (i+1)%100 == 0:\n",
        "        print(f'Iteration {i+1}')\n",
        "        print(test_all_inputs(inputs, params))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 100\n",
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 0\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 200\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 0\n",
            "[1 1] -> 1\n",
            "False\n",
            "Iteration 300\n",
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 0\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 400\n",
            "[0 0] -> 1\n",
            "[0 1] -> 0\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 500\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 1\n",
            "False\n",
            "Iteration 600\n",
            "[0 0] -> 0\n",
            "[0 1] -> 1\n",
            "[1 0] -> 0\n",
            "[1 1] -> 1\n",
            "False\n",
            "Iteration 700\n",
            "[0 0] -> 0\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 1\n",
            "False\n",
            "Iteration 800\n",
            "[0 0] -> 0\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 1\n",
            "False\n",
            "Iteration 900\n",
            "[0 0] -> 0\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 1\n",
            "False\n",
            "Iteration 1000\n",
            "[0 0] -> 0\n",
            "[0 1] -> 0\n",
            "[1 0] -> 0\n",
            "[1 1] -> 0\n",
            "False\n",
            "CPU times: user 4.53 s, sys: 1.06 s, total: 5.6 s\n",
            "Wall time: 4.29 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IghUjYPfmCu5",
        "colab_type": "text"
      },
      "source": [
        "## batching using `jax.vmap`\n",
        "\n",
        "for `jax.vmap`:\n",
        "\n",
        "`in_axes`: what axes of the input to parallelize over\n",
        "- using `(None, 0, 0)` to for `(params, x, y)` since we want to parallelize the 0th dim for x, y, but not parallelize for params\n",
        "\n",
        "`out_axes`: what axes of the output to parallelize over\n",
        "- 0 because 0th dim for output (the gradients)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_fyd8D2lCny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_grad = jax.jit(jax.vmap(jax.grad(loss), in_axes =(None, 0, 0), out_axes=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLdZ1Ed-nM3P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a034bbd-87a2-4884-e018-bf730c654ee1"
      },
      "source": [
        "%%time\n",
        "params = init_params()\n",
        "lr = 1e-1\n",
        "bs = 128\n",
        "for i in range(1000):\n",
        "    x = inputs[onp.random.choice(inputs.shape[0], size = bs)] # grab 1 sample\n",
        "    y = onp.bitwise_xor(x[:, 0], x[:, 1]) # getting y for a batch of x's\n",
        "    grads = loss_grad(params, x, y)\n",
        "    #update gradients\n",
        "    params = [p-lr*np.mean(g, axis=0)\n",
        "        for p, g, in zip(params, grads)] # grabbing the mean of loss across a batch\n",
        "\n",
        "    # print stats\n",
        "    if (i+1)%100 == 0:\n",
        "        print(f'Iteration {i+1}')\n",
        "        print(test_all_inputs(inputs, params))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 100\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 200\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 300\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 400\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 500\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 600\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 700\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 800\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 900\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "Iteration 1000\n",
            "[0 0] -> 1\n",
            "[0 1] -> 1\n",
            "[1 0] -> 1\n",
            "[1 1] -> 0\n",
            "False\n",
            "CPU times: user 10.8 s, sys: 2.68 s, total: 13.5 s\n",
            "Wall time: 10.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rAuzmimobIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}