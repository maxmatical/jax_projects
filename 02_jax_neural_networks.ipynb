{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_jax_neural_networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNokUEJVljc8x8ptBvEopVi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxmatical/jax_projects/blob/master/02_jax_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQOA1P2BgIbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax.numpy as np\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubcZcvZDgX07",
        "colab_type": "text"
      },
      "source": [
        "defining hyperparams for NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8_T4Kr1gT5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_layer_params(m, n, key, scale = 1e-2):\n",
        "  # initialize the weights and bias for a hidden layer\n",
        "  w, b = random.split(key)\n",
        "  return scale*random.normal(w, (n,m)), scale*random.normal(b, (n,))\n",
        "\n",
        "def init_nn_params(sizes, key):\n",
        "  keys = random.split(key, len(sizes))\n",
        "  return [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
        "\n",
        "# definig parameters of the nn\n",
        "\n",
        "szs = [28*28, 512, 256, 10] # flattened input will be 28*28\n",
        "param_scale = 0.1\n",
        "lr = 0.01\n",
        "n_epochs = 10\n",
        "bs = 128\n",
        "n_classes = 10\n",
        "\n",
        "params = init_nn_params(szs, random.PRNGKey(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE6vKeGRjTxT",
        "colab_type": "text"
      },
      "source": [
        "defining NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVjt2-FejTGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def net(params, input):\n",
        "  # forward pass for a sinlge input\n",
        "  out = input\n",
        "  for w, b in params[:-1]: # go through hidden layers until classifier layer\n",
        "    out = np.dot(w, out) + b\n",
        "    out = relu(out)\n",
        "  w_clas, b_clas = params[-1]\n",
        "  logits = np.dot(w_clas, out)+b_clas\n",
        "  # return logits\n",
        "  return logits -logsumexp(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQR6s7ugj_8d",
        "colab_type": "text"
      },
      "source": [
        "checking to see if it works on a single sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tuxs74fTjHiN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94bac5f0-8469-44b4-876c-3f4a7b712e09"
      },
      "source": [
        "rand_input = random.normal(random.PRNGKey(1), (28*28,))\n",
        "preds = net(params, rand_input)\n",
        "print(preds.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6H9OpdPkVAw",
        "colab_type": "text"
      },
      "source": [
        "using `vmap` to generate batch predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVMl-pTCkR0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dacb1cb7-6261-4dc3-81c1-0ee6f923f6ce"
      },
      "source": [
        "forward_batch = vmap(net, in_axes = (None, 0))\n",
        "rand_input_batch = random.normal(random.PRNGKey(1), (128, 28*28,))\n",
        "batch_preds = forward_batch(params, rand_input_batch)\n",
        "print(batch_preds.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omWdK3FclJ-H",
        "colab_type": "text"
      },
      "source": [
        "defining metrics and loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yix7q7-QkzrB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(x, k, dtype = np.float32):\n",
        "  # create 1-hot encoding of size k\n",
        "  return np.array(x[:, None] == np.arrange(k), dtype)\n",
        "\n",
        "\n",
        "\n",
        "def accuracy(params, input, targets):\n",
        "\n",
        "def loss(params, input, targets):\n",
        "  preds = forward_batch(params, input)\n",
        "  return -np.mean(preds*targets)\n",
        "\n",
        "def cross_entropy_loss(params, input, targets):\n",
        "  # TODO\n",
        "  # loss with just logits\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}